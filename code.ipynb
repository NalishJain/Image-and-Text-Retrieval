{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.4.1.post1-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.12.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (112 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.4.1.post1-cp310-cp310-macosx_12_0_arm64.whl (10.4 MB)\n",
      "Using cached scipy-1.12.0-cp310-cp310-macosx_12_0_arm64.whl (31.4 MB)\n",
      "Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.3.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas numpy nltk tensorflow matplotlib pillow\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image, ImageEnhance\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nalishjain/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nalishjain/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nalishjain/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"A2_Data.csv\")\n",
    "df = df.dropna()\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Image</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3452</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Loving these vintage springs on my vintage str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1205</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Works great as a guitar bench mat. Not rugged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1708</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>We use these for everything from our acoustic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2078</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Great price and good quality.  It didn't quite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>I bought this bass to split time as my primary...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                              Image  \\\n",
       "0  3452  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "1  1205  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "2  1708  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "3  2078  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "4   801  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "\n",
       "                                         Review Text  \n",
       "0  Loving these vintage springs on my vintage str...  \n",
       "1  Works great as a guitar bench mat. Not rugged ...  \n",
       "2  We use these for everything from our acoustic ...  \n",
       "3  Great price and good quality.  It didn't quite...  \n",
       "4  I bought this bass to split time as my primary...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "image_text_dict = {}\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    urls = row['Image']\n",
    "    url_list = json.loads(urls.replace(\"'\", \"\\\"\"))\n",
    "    text = row['Review Text']\n",
    "    image_text_dict[count] = [url_list,text]\n",
    "    count += 1\n",
    "print(len(image_text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_prod = np.dot(vector1, vector2)\n",
    "    mag_vector1 = np.linalg.norm(vector1)\n",
    "    mag_vector2 = np.linalg.norm(vector2)\n",
    "\n",
    "    if mag_vector1 == 0 or mag_vector2 == 0:\n",
    "        return 0  \n",
    "    return dot_prod / (mag_vector1 * mag_vector2)\n",
    "\n",
    "def find_top_similar_keys(query_vector, vectors_dict, top_n=3):\n",
    "    similarities = {}\n",
    "\n",
    "    for key, vectors in vectors_dict.items():\n",
    "        similarities[key] = 0\n",
    "        for vector in vectors:\n",
    "            similarities[key] = max(cosine_similarity(query_vector, vector), similarities[key])\n",
    "\n",
    "    sorted_keys = sorted(similarities, key=similarities.get, reverse=True)\n",
    "    top_keys = sorted_keys[:top_n]\n",
    "    top_scores = [similarities[key] for key in top_keys]\n",
    "\n",
    "    return top_keys, top_scores\n",
    "\n",
    "def find_top_similar_keys_2(img_query_vector, text_query_vector, img_dict, text_dict, top_n=3):\n",
    "    similarities = {}\n",
    "\n",
    "    for key, vectors in img_dict.items():\n",
    "        similarities[key] = 0\n",
    "        text_score = cosine_similarity(text_query_vector, text_dict[key][0])\n",
    "        for vector in vectors:\n",
    "            similarities[key] = max((cosine_similarity(img_query_vector, vector) + text_score)/2, similarities[key])\n",
    "\n",
    "    sorted_keys = sorted(similarities, key=similarities.get, reverse=True)\n",
    "    top_keys = sorted_keys[:top_n]\n",
    "    top_scores = [similarities[key] for key in top_keys]\n",
    "\n",
    "    return top_keys, top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_url, factor = 1.2):\n",
    "    response = requests.get(img_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    img = img.resize((224, 224)) \n",
    "    enhancer = ImageEnhance.Brightness(img) \n",
    "    img = enhancer.enhance(factor)\n",
    "\n",
    "    datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True) \n",
    "\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    iterator = datagen.flow(img_array)\n",
    "    img_array = next(iterator)\n",
    "    # img_array =  datagen.flow(img_array).next()\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "def extract_image_features(model, img_array):\n",
    "    features = model.predict(img_array)\n",
    "    features = features.flatten()\n",
    "    return features\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Removing punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    # Stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Url 67\n",
      "Invalid Url 67\n",
      "Invalid Url 110\n",
      "Invalid Url 110\n",
      "Invalid Url 523\n",
      "Invalid Url 701\n",
      "Invalid Url 859\n",
      "Invalid Url 935\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "invalid_url_ids = []\n",
    "for i in range(len(image_text_dict)):\n",
    "    valid_urls = []\n",
    "    for img_url in image_text_dict[i][0]:\n",
    "        try:\n",
    "            Image.open(BytesIO(requests.get(img_url).content))\n",
    "            valid_urls.append(img_url)\n",
    "        except:\n",
    "            print(\"Invalid Url\", i)\n",
    "    image_text_dict[i][0] = valid_urls\n",
    "# image_text_dict = {key: value for key, value in image_text_dict.items() if key not in invalid_url_ids}\n",
    "print(len(image_text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_text_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(image_text_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet')\n",
    "image_model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_text_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m url_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mimage_text_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m img_features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m img_feature_urls \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_text_dict' is not defined"
     ]
    }
   ],
   "source": [
    "url_ids = list(image_text_dict.keys())\n",
    "\n",
    "img_features = []\n",
    "img_feature_urls = []\n",
    "img_features_dict = {}\n",
    "\n",
    "for url_id in url_ids:   \n",
    "    for img_url in image_text_dict[url_id][0]:\n",
    "        img_array = preprocess_image(img_url)\n",
    "        img_feature = extract_image_features(image_model, img_array)\n",
    "        img_features.append(img_feature.reshape(4096))\n",
    "        img_feature_urls.append(url_id)\n",
    "\n",
    "img_features = normalize(np.array(img_features), norm='l2', axis=1)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for url_id in img_feature_urls:\n",
    "    img_features_dict[url_id] = []\n",
    "\n",
    "for url_id in img_feature_urls:\n",
    "    img_features_dict[url_id].append(img_features[count])\n",
    "    count +=1\n",
    "\n",
    "with open('img_features_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(img_features_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993\n"
     ]
    }
   ],
   "source": [
    "print(len(set(img_features_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{67, 110, 523, 701, 859, 935}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_ids = set(image_text_dict.keys())\n",
    "url_ids.difference(set(img_features_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ids = list(img_features_dict.keys())\n",
    "text_reviews = {}\n",
    "for url_id in url_ids:\n",
    "    pp_text = preprocess_text(image_text_dict[url_id][1])\n",
    "    text_reviews[url_id] = pp_text\n",
    "# print(text_reviews)\n",
    "\n",
    "tf = {}\n",
    "idf = {}\n",
    "tf_idf = {}\n",
    "word_id = {}\n",
    "word_id_iter = 0\n",
    "for url_id in text_reviews.keys():\n",
    "    # calculating idf\n",
    "    word_list = text_reviews[url_id].split()\n",
    "\n",
    "    tf[url_id] = {}\n",
    "    for word in set(word_list):\n",
    "        if word not in idf:\n",
    "            idf[word] = 1\n",
    "            word_id[word] = word_id_iter\n",
    "            word_id_iter += 1\n",
    "        else:\n",
    "            idf[word] += 1\n",
    "    # calculating tf\n",
    "    for word in word_list:\n",
    "        if word not in tf[url_id]:\n",
    "            tf[url_id][word] = 1 \n",
    "        else:\n",
    "            tf[url_id][word] += 1             \n",
    "\n",
    "for url_id in text_reviews.keys():\n",
    "    word_list = text_reviews[url_id].split()\n",
    "    tf_idf[url_id] = [np.zeros(shape = (len(idf)))]\n",
    "\n",
    "    for word in set(word_list): \n",
    "        # tf_idf[url_id][0][word_id[word]] = np.log(len(image_text_dict)/idf[word])*tf[url_id][word]/len(word_list)       \n",
    "        tf_idf[url_id][0][word_id[word]] = np.log(len(image_text_dict)/idf[word])*tf[url_id][word] \n",
    "  \n",
    "\n",
    "# print(tf_idf[0])\n",
    "# print(word_id)\n",
    "# print(tf_idf[0].shape)\n",
    "with open('tf_idf.pkl', 'wb') as f:\n",
    "    pickle.dump(tf_idf, f)\n",
    "\n",
    "with open('idf.pkl', 'wb') as f:\n",
    "    pickle.dump(idf, f)\n",
    "\n",
    "with open('word_id.pkl', 'wb') as f:\n",
    "    pickle.dump(word_id, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6046\n"
     ]
    }
   ],
   "source": [
    "print(len(idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'img_features_dict.pkl'\n",
    "with open(file_path, 'rb') as pickle_file:\n",
    "    img_features_dict = pickle.load(pickle_file)\n",
    "\n",
    "file_path = 'tf_idf.pkl'\n",
    "with open(file_path, 'rb') as pickle_file:\n",
    "    tf_idf = pickle.load(pickle_file)\n",
    "\n",
    "file_path = 'image_text_dict.pkl'\n",
    "with open(file_path, 'rb') as pickle_file:\n",
    "    image_text_dict = pickle.load(pickle_file)\n",
    "\n",
    "file_path = 'idf.pkl'\n",
    "with open(file_path, 'rb') as pickle_file:\n",
    "    idf = pickle.load(pickle_file)\n",
    "\n",
    "file_path = 'word_id.pkl'\n",
    "with open(file_path, 'rb') as pickle_file:\n",
    "    word_id = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input(img_url, text):\n",
    "    img_array = preprocess_image(img_url)\n",
    "    img_vector = extract_image_features(image_model, img_array).reshape(4096)\n",
    "    top_url_ids_img, cosine_scores_img = find_top_similar_keys(img_vector, img_features_dict)\n",
    "\n",
    "    pp_text =  preprocess_text(text)\n",
    "    words = pp_text.split(\" \")\n",
    "    text_vector = np.zeros(shape = (6046))\n",
    "\n",
    "    freq_words = {}\n",
    "    for word in words: \n",
    "        if word not in freq_words:\n",
    "            freq_words[word] = 1\n",
    "        else:\n",
    "            freq_words[word] += 1\n",
    "    \n",
    "    for word in set(words):\n",
    "        # text_vector[word_id[word]] = freq_words[word]*np.log(len(image_text_dict)/idf[word])/len(words)     \n",
    "        text_vector[word_id[word]] = freq_words[word]*np.log(len(image_text_dict)/idf[word])    \n",
    "    \n",
    "    top_url_ids_text, cosine_scores_text = find_top_similar_keys(text_vector, tf_idf)\n",
    "\n",
    "    top_url_ids_composite, cosine_scores_text = find_top_similar_keys_2(img_vector, text_vector, img_features_dict, tf_idf)\n",
    "    \n",
    "    print(\"Using Image Retreival\")\n",
    "    print(\"1. Image Url :\" , image_text_dict[top_url_ids_img[0]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_img[0]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_img[0]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_img[0]][0]))\n",
    "    print(\"   Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_img[0]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_img[0]][0]))/2)\n",
    "\n",
    "    print(\"2. Image Url :\" , image_text_dict[top_url_ids_img[1]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_img[1]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_img[1]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_img[1]][0]))\n",
    "    print(\"   Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_img[1]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_img[1]][0]))/2)\n",
    "\n",
    "\n",
    "    print(\"3. Image Url :\" , image_text_dict[top_url_ids_img[2]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_img[2]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_img[2]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_img[2]][0]))\n",
    "    print(\"   Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_img[2]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_img[2]][0]))/2)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(\"Using text Retreival\")\n",
    "    print(\"1. Image Url :\" , image_text_dict[top_url_ids_text[0]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_text[0]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_text[0]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_text[0]][0]))\n",
    "    print(\"   Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_text[0]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_text[0]][0]))/2)\n",
    "\n",
    "\n",
    "    print(\"2. Image Url :\" , image_text_dict[top_url_ids_text[1]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_text[1]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_text[1]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_text[1]][0]))\n",
    "    print(\"   Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_text[1]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_text[1]][0]))/2)\n",
    "\n",
    "\n",
    "    print(\"3. Image Url :\" , image_text_dict[top_url_ids_text[2]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_text[2]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_text[2]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_text[2]][0]))             \n",
    "    print(\"   Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_text[2]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_text[2]][0]))/2)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(\"Using Composite Retreival\")\n",
    "    print(\"1. Image Url :\" , image_text_dict[top_url_ids_composite[0]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_composite[0]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_composite[0]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_composite[0]][0]))\n",
    "    print(\" Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_composite[0]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_composite[0]][0]))/2)\n",
    "\n",
    "    print(\"2. Image Url :\" , image_text_dict[top_url_ids_composite[1]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_composite[1]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_composite[1]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_composite[1]][0]))\n",
    "    print(\" Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_composite[1]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_composite[1]][0]))/2)\n",
    "\n",
    "    print(\"3. Image Url :\" , image_text_dict[top_url_ids_composite[2]][0])\n",
    "    print(\"   Review : \", image_text_dict[top_url_ids_composite[2]][1])\n",
    "    print(\"   Cosine score of images : \", cosine_similarity(img_vector, img_features_dict[top_url_ids_composite[2]][0]))\n",
    "    print(\"   Cosine score of text : \", cosine_similarity(text_vector, tf_idf[top_url_ids_composite[2]][0]))  \n",
    "    print(\" Composite score : \", (cosine_similarity(img_vector, img_features_dict[top_url_ids_composite[2]][0])+cosine_similarity(text_vector, tf_idf[top_url_ids_composite[2]][0]))/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "Using Image Retreival\n",
      "1. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg']\n",
      "   Review :  I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.\n",
      "   Cosine score of images :  1.0\n",
      "   Cosine score of text :  1.0\n",
      "   Composite score :  1.0\n",
      "2. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/719-SDMiOoL._SY88.jpg']\n",
      "   Review :  These locking tuners look great and keep tune.  Good quality materials and construction.  Excellent upgrade to any guitar.  I had to drill additions holes for installation.  If your neck already comes with pre-drilled holes, then they should drop right in, otherwise you will need to buy a guitar tuner pin drill jig, also available from Amazon.\n",
      "   Cosine score of images :  0.7406116\n",
      "   Cosine score of text :  0.1041278203226515\n",
      "   Composite score :  0.42236971655971745\n",
      "3. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/711kGbkdzEL._SY88.jpg']\n",
      "   Review :  Had to drill into my headstock. Needs 2 holes per tree because of the mounting peg. Use a ruler and a 1/16 drillbit and you'll be fine. I recommend installing with the strings on so you can set them properly.\n",
      "   Cosine score of images :  0.62808\n",
      "   Cosine score of text :  0.0\n",
      "   Composite score :  0.31404000520706177\n",
      "\n",
      "Using text Retreival\n",
      "1. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg']\n",
      "   Review :  I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.\n",
      "   Cosine score of images :  1.0\n",
      "   Cosine score of text :  1.0\n",
      "   Composite score :  1.0\n",
      "2. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/61DvLcapd8L._SY88.jpg']\n",
      "   Review :  I went from fender chrome non-locking to fender gold locking. It made my guitar look beautiful and play beautiful. I think locking tuners are the way to go. If you are new to locking tuners look on YouTube for instructions.\n",
      "   Cosine score of images :  0.32125974\n",
      "   Cosine score of text :  0.2694440574603408\n",
      "   Composite score :  0.2953518972375556\n",
      "3. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/61clqkZnKxL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/61NeE5N1eQL._SY88.jpg']\n",
      "   Review :  Now all I have to do is install these on my Burswood Strat Copy. I know I'm gonna have to drill holes for the locating pins I may even have to drill the tuner holes also. Look forward to getting those crappy, loose, un-smooth, original hardware tuners off this thing.\n",
      "\n",
      "July 20, 2012:\n",
      "  Just installed these Fender locking tuners on my Strat. Didn't have to drill the tuner holes, they were the perfect size. Placed all the tuners in the headstock lined them up with a straight edge and just pressed each tuner very firmly into their hole (with the locking part screwed in tight so as not to damage them) and  very lightly and carefully tapped them with a small rubber mallet to mark my drill points. Then with a small magnifying glass and using a punch I made a center punch mark (just using pressure by hand with the punch since wood is soft) on each indent that the tuner made. Set my drill depth with a piece of tape on the drill and was done in less than 15 minutes.\n",
      "   Cosine score of images :  0.50057656\n",
      "   Cosine score of text :  0.14242119035998793\n",
      "   Composite score :  0.32149887304445013\n",
      "\n",
      "Using Composite Retreival\n",
      "1. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg']\n",
      "   Review :  I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.\n",
      "   Cosine score of images :  1.0\n",
      "   Cosine score of text :  1.0\n",
      " Composite score :  1.0\n",
      "2. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/719-SDMiOoL._SY88.jpg']\n",
      "   Review :  These locking tuners look great and keep tune.  Good quality materials and construction.  Excellent upgrade to any guitar.  I had to drill additions holes for installation.  If your neck already comes with pre-drilled holes, then they should drop right in, otherwise you will need to buy a guitar tuner pin drill jig, also available from Amazon.\n",
      "   Cosine score of images :  0.7406116\n",
      "   Cosine score of text :  0.1041278203226515\n",
      " Composite score :  0.42236971655971745\n",
      "3. Image Url : ['https://images-na.ssl-images-amazon.com/images/I/61clqkZnKxL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/61NeE5N1eQL._SY88.jpg']\n",
      "   Review :  Now all I have to do is install these on my Burswood Strat Copy. I know I'm gonna have to drill holes for the locating pins I may even have to drill the tuner holes also. Look forward to getting those crappy, loose, un-smooth, original hardware tuners off this thing.\n",
      "\n",
      "July 20, 2012:\n",
      "  Just installed these Fender locking tuners on my Strat. Didn't have to drill the tuner holes, they were the perfect size. Placed all the tuners in the headstock lined them up with a straight edge and just pressed each tuner very firmly into their hole (with the locking part screwed in tight so as not to damage them) and  very lightly and carefully tapped them with a small rubber mallet to mark my drill points. Then with a small magnifying glass and using a punch I made a center punch mark (just using pressure by hand with the punch since wood is soft) on each indent that the tuner made. Set my drill depth with a piece of tape on the drill and was done in less than 15 minutes.\n",
      "   Cosine score of images :  0.50057656\n",
      "   Cosine score of text :  0.14242119035998793\n",
      " Composite score :  0.32149887304445013\n"
     ]
    }
   ],
   "source": [
    "test_url = 'https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg'\n",
    "test_text = 'I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.'\n",
    "user_input(test_url, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_img_url = image_text_dict[70][0]\n",
    "# preprocessed_img_array = preprocess_image(example_img_url, factor = 1.2)\n",
    "# print(preprocessed_img_array.shape)\n",
    "# # Convert the preprocessed image array back to a PIL Image for visualization\n",
    "# preprocessed_img = image.array_to_img(preprocessed_img_array[0])\n",
    "\n",
    "# # Display the original and preprocessed images\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.title(\"Original Image\")\n",
    "# plt.imshow(Image.open(BytesIO(requests.get(example_img_url).content)))\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.title(\"Preprocessed Image\")\n",
    "# plt.imshow(preprocessed_img)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
